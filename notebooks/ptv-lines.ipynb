{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import shapely.geometry as sg\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString, MultiLineString, Point, MultiPoint\n",
    "from shapely.ops import unary_union\n",
    "data_directory = os.path.join('..', 'data', 'ptv', '20240224')\n",
    "\n",
    "\n",
    "\n",
    "ROUTE_TYPES = {\n",
    "    0 : 'Tram',\n",
    "    1 : 'Metro',\n",
    "    2 : 'Rail',\n",
    "    3 : 'Bus',\n",
    "    4 : 'Ferry',\n",
    "    5 : 'Cable tram',\n",
    "    6 : 'Gondola',\n",
    "    7 : 'Funicular',\n",
    "    11 : 'Trolleybus',\n",
    "    12 : 'Monorail',\n",
    "}\n",
    "ROUTE_TYPES_LONG = {\n",
    "    0 : 'Tram, Streetcar, Light rail. Any light rail or street level system within a metropolitan area.',\n",
    "    1 : 'Subway, Metro. Any underground rail system within a metropolitan area.',\n",
    "    2 : 'Rail. Used for intercity or long-distance travel.',\n",
    "    3 : 'Bus. Used for short- and long-distance bus routes.',\n",
    "    4 : 'Ferry. Used for short- and long-distance boat service.',\n",
    "    5 : 'Cable tram. Used for street-level rail cars where the cable runs beneath the vehicle, e.g., cable car in San Francisco.',\n",
    "    6 : 'Aerial lift, suspended cable car (e.g., gondola lift, aerial tramway). Cable transport where cabins, cars, gondolas or open chairs are suspended by means of one or more cables.',\n",
    "    7 : 'Funicular. Any rail system designed for steep inclines.',\n",
    "    11 : 'Trolleybus. Electric buses that draw power from overhead wires using poles.',\n",
    "    12 : 'Monorail. Railway in which the track consists of a single rail or a beam.',\n",
    "}\n",
    "\n",
    "BRANCH_IDS_ALL = ['1', '2', '3', '4', '5', '6', '7', '8', '10', '11']\n",
    "BRANCH_IDS = ['1', '2', '3', '4', '5', '6', '10', '11']\n",
    "TABLE_NAMES = ['stop_times', 'stops', 'trips', 'routes', 'calendar', 'calendar_dates', 'agency', 'shapes']\n",
    "# GTFS File Fields\n",
    "# agency.txt \n",
    "# agency_id, agency_name, agency_url, agency_timezone, agency_lang\n",
    "# calendar.txt \n",
    "# service_id, monday, tuesday, wednesday, thursday, friday, saturday, sunday, start_date, end_date\n",
    "# calendar_dates.txt \n",
    "# service_id ,date, exception_type\n",
    "# routes.txt \n",
    "# route_id, agency_id, route_short_name, route_long_name,\n",
    "# route_type, route_color,route_text_color\n",
    "# trips.txt \n",
    "# route_id, service_id, trip_id, shape_id, trip_headsign, direction_id\n",
    "# stops.txt \n",
    "# stop_id, stop_name, stop_lat, stop_lon\n",
    "# stop_times.txt \n",
    "# trip_id, arrival_time, departure_time, stop_id, stop_sequence, stop_headsign, pickup_type, drop_off_type, shape_dist_traveled\n",
    "# shapes.txt \n",
    "# shape_id, shape_pt_lat, shape_pt_lon, shape_pt_sequence, shape_dist_traveled \n",
    "def get_df(branch_id, table_name):\n",
    "    files = [os.path.join(data_directory, f) for f in os.listdir(data_directory) if f.split('-')[1] == str(branch_id) and f.split('-')[2] == table_name]\n",
    "    if len(files) == 0:\n",
    "        return None\n",
    "    return pd.concat([pd.read_csv(f, keep_default_na=False, na_values=['']) for f in files])\n",
    "\n",
    "DF = {branch_id: {table_name: get_df(branch_id, table_name) for table_name in TABLE_NAMES} for branch_id in BRANCH_IDS_ALL}\n",
    "# 15s - 30s\n",
    "\n",
    "\n",
    "for bid in BRANCH_IDS:\n",
    "    DF[bid]['shapes'].sort_values(by=['shape_id', 'shape_pt_sequence'], inplace=True)\n",
    "    DF[bid]['shapes']['points'] = list(zip(DF[bid]['shapes']['shape_pt_lon'], DF[bid]['shapes']['shape_pt_lat']))\n",
    "    DF[bid]['lines'] = DF[bid]['shapes'].groupby('shape_id')['points'].apply(np.array).rename('line').reset_index()\n",
    "    DF[bid]['lines']['direction'] = DF[bid]['lines']['shape_id'].transform(lambda x: x.split('.')[-1])\n",
    "    DF[bid]['lines']['route_id'] = DF[bid]['lines']['shape_id'].transform(lambda x: x.split('.')[0])\n",
    "    DF[bid]['lines']['route_name'] = DF[bid]['lines']['route_id'].transform(lambda x: ''.join(x.split('-')[1:-2]))\n",
    "    DF[bid]['lines']['branch'] = DF[bid]['lines']['route_id'].transform(lambda x: x.split('-')[0])\n",
    "    DF[bid]['lines']['opbranch'] = bid\n",
    "\n",
    "# Total 2m    \n",
    "    \n",
    "DFLINES : pd.DataFrame = pd.concat([DF[bid]['lines'] for bid in BRANCH_IDS])\n",
    "\n",
    "DFLINES['points_count'] = DFLINES['line'].apply(len)\n",
    "\n",
    "DFLINES = DFLINES[['route_name', 'direction', 'branch', 'opbranch', 'route_id', 'shape_id', 'line', 'points_count']]\n",
    "\n",
    "DFLINES.sort_values(\n",
    "    by=['opbranch', 'route_name', 'branch', 'direction', 'points_count'], \n",
    "    ascending=[True, True, True, True, False],\n",
    "    inplace=True, \n",
    ")\n",
    "\n",
    "DFLINES.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Total: 1m 30s - 2m\n",
    "\n",
    "def find_smallest_number_of_lists(lists):\n",
    "    # Create a set to store all unique elements from all lists\n",
    "    all_elements = set()\n",
    "    for lst in lists:\n",
    "        all_elements.update(lst)\n",
    "\n",
    "    # Initialize an empty list to store the selected lists\n",
    "    selected_lists = []\n",
    "\n",
    "    # Iterate until all elements are covered\n",
    "    while all_elements:\n",
    "        # Find the list that covers the maximum number of uncovered elements\n",
    "        max_covered = set()\n",
    "        max_list = None\n",
    "        for lst in lists:\n",
    "            covered = set(lst).intersection(all_elements)\n",
    "            if len(covered) > len(max_covered):\n",
    "                max_covered = covered\n",
    "                max_list = lst\n",
    "\n",
    "        # Remove covered elements from the set of all elements\n",
    "        all_elements.difference_update(max_covered)\n",
    "\n",
    "        # Add the selected list to the result\n",
    "        selected_lists.append(max_list)\n",
    "\n",
    "    return selected_lists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFLINES['segments'] = DFLINES['line'].apply(lambda x: [(x[i], x[i+1]) for i in range(len(x)-1)])\n",
    "# 10s - 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SEGMENTS = DFLINES.explode('segments').reset_index(drop=True)\n",
    "# 10s - 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SEGMENTS = DF_SEGMENTS[['route_name', 'direction', 'branch', 'opbranch', 'route_id', 'shape_id', 'segments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SEGMENTS_MIN = DF_SEGMENTS.drop_duplicates(subset=['route_name', 'direction', 'opbranch', 'segments'], keep='first')[['route_name', 'direction', 'opbranch', 'segments']]\n",
    "# 12s - 20s\n",
    "DF_SEGMENTS_MIN = DF_SEGMENTS_MIN.groupby(['route_name', 'direction', 'opbranch'])['segments'].apply(np.array).reset_index()\n",
    "DF_SEGMENTS_MIN['segments'] = DF_SEGMENTS_MIN['segments'].transform(lambda segments: np.array([np.array([np.array(p) for p in segment]) for segment in segments]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_directed_paths(input_paths : np.ndarray[np.ndarray[np.ndarray]]) -> np.ndarray[np.ndarray[np.ndarray]]:\n",
    "    # Make sure input_paths is a numpy array of numpy arrays of numpy arrays\n",
    "    input_paths = np.array([np.array([np.array(p) for p in path]) for path in input_paths])\n",
    "    merged_paths = []\n",
    "    for path in input_paths:\n",
    "        merged = False\n",
    "        for i, existing_path in enumerate(merged_paths):\n",
    "            if all(path[0] == existing_path[-1]):\n",
    "                merged_paths[i] = np.concatenate([existing_path, path[1:]], axis=0)\n",
    "                merged = True\n",
    "                break\n",
    "            elif all(path[-1] == existing_path[0]):\n",
    "                merged_paths[i] = np.concatenate([path[:-1], existing_path], axis=0)\n",
    "                merged = True\n",
    "                break\n",
    "        if not merged:\n",
    "            merged_paths.append(path)\n",
    "\n",
    "    # Remove consecutive duplicates\n",
    "    for i, path in enumerate(merged_paths):\n",
    "        merged_paths[i] = path[np.concatenate([[True], np.any(path[1:] != path[:-1], axis=1)])]\n",
    "\n",
    "    # Remove paths that are < 2 points\n",
    "    merged_paths = [path for path in merged_paths if len(path) > 1]\n",
    "    return merged_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SEGMENTS_MIN['paths'] = DF_SEGMENTS_MIN['segments'].apply(lambda x: merge_directed_paths(x))\n",
    "# 7s - 15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SEGMENTS_MIN['segments_count'] = DF_SEGMENTS_MIN['segments'].apply(len)\n",
    "DF_SEGMENTS_MIN['paths_count'] = DF_SEGMENTS_MIN['paths'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_SEGMENTS_MIN['geometry'] = DF_SEGMENTS_MIN['paths'].apply(lambda x: MultiLineString(x) if len(x) > 1 else LineString(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF = gpd.GeoDataFrame(DF_SEGMENTS_MIN[['route_name', 'direction', 'opbranch', 'geometry']], geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF.to_file('../data/ptv/ptv-lines.geojson', driver='GeoJSON')\n",
    "# 5s - 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDF.groupby('opbranch').apply(lambda x: x.to_file(f'../data/ptv/ptv-lines-{x.name}.geojson', driver='GeoJSON'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DFLINESMULTI = DFLINES.groupby(['route_name', 'opbranch', 'direction'])['line'].apply(np.array).rename('lines').reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DFLINESMULTI['geo_full'] = DFLINESMULTI['lines'].apply(lambda x: [LineString(i) for i in x])\n",
    "DFLINESMULTI['union_full'] = DFLINESMULTI['geo_full'].apply(unary_union)\n",
    "DFLINESMULTI['geom_full_count'] = DFLINESMULTI['union_full'].apply(lambda x: len(x.geoms) if x.geom_type == 'MultiLineString' else 1)\n",
    "# 12m - 15m\n",
    "\n",
    "\n",
    "DFLINESGEOFULL = DFLINESMULTI[['route_name', 'opbranch', 'direction', 'union_full', 'geom_full_count']]\n",
    "\n",
    "# Convert linestring to array of points\n",
    "DFLINESGEOFULL['points_full'] = DFLINESGEOFULL['union_full'].apply(lambda x: np.array(x.geoms) if x.geom_type == 'MultiLineString' else np.array([x]))\n",
    "# 5s - 10s\n",
    "DFLINESGEOFULL = DFLINESGEOFULL.explode('points_full').reset_index(drop=True)\n",
    "DFLINESGEOFULL['points_full'] = DFLINESGEOFULL['points_full'].apply(lambda x: np.array(x.coords))\n",
    "# 5s - 10s\n",
    "DFLINESGEOFULL['points_len'] = DFLINESGEOFULL['points_full'].apply(len)\n",
    "DFLINESGEOFULL = DFLINESGEOFULL[['route_name', 'opbranch', 'direction', 'points_full', 'points_len']]\n",
    "\n",
    "DFLINESGEOFULL = DFLINESGEOFULL.groupby(['route_name', 'opbranch', 'direction'])['points_full'].apply(np.array).reset_index()\n",
    "DFLINESGEOFULL.rename(columns={'points_full': 'lines'}, inplace=True)\n",
    "DFLINESGEOFULL['lines_count'] = DFLINESGEOFULL['lines'].apply(len)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DFLINESGEOFULL['paths'] = DFLINESGEOFULL['lines'].transform(lambda x: merge_directed_paths(x))\n",
    "# 5s -10s\n",
    "DFLINESGEOFULL['paths_count'] = DFLINESGEOFULL['paths'].apply(len)\n",
    "\n",
    "\n",
    "DFLINESGEOFULL.sort_values(by='paths_count', ascending=False, inplace=True)\n",
    "DFLINESGEOFULL.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "DFLINESGEOFULL['geo_lines'] = DFLINESGEOFULL['lines'].apply(lambda x: MultiLineString([LineString(i) for i in x]))\n",
    "# 10s - 15s\n",
    "\n",
    "\n",
    "DFLINESGEOFULL['geo_paths'] = DFLINESGEOFULL['paths'].apply(lambda x: MultiLineString([LineString(i) for i in x]) if len(x) > 1 else LineString(x[0]))\n",
    "\n",
    "\n",
    "GDF_LINES = DFLINESGEOFULL[['route_name', 'opbranch', 'direction', 'geo_paths']]\n",
    "GDF_LINES = gpd.GeoDataFrame(GDF_LINES, geometry='geo_paths')\n",
    "\n",
    "\n",
    "GDF_LINES.rename(columns={'opbranch': 'opbranch'}, inplace=True)\n",
    "\n",
    "\n",
    "GDF_LINES.sort_values(by=['opbranch', 'route_name', 'direction'], inplace=True)\n",
    "\n",
    "\n",
    "GDF_LINES.to_file('../data/ptv/ptv-lines.geojson', driver='GeoJSON')\n",
    "# 20s\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
